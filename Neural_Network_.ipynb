{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41000, 784) (41000,) float64 int64\n",
      "(1000, 784) (1000,) float64 int64\n",
      "0.05504878048780488\n",
      "loss: 2.299022\n",
      "loss: 2.911965\n",
      "loss: 3.659386\n",
      "loss: 2.977325\n",
      "loss: 2.026787\n",
      "loss: 1.732727\n",
      "loss: 1.479065\n",
      "loss: 1.245843\n",
      "loss: 1.069211\n",
      "loss: 0.940110\n",
      "loss: 0.842202\n",
      "loss: 0.766053\n",
      "loss: 0.706350\n",
      "loss: 0.659124\n",
      "loss: 0.621186\n",
      "loss: 0.590141\n",
      "loss: 0.564273\n",
      "loss: 0.542376\n",
      "loss: 0.523596\n",
      "loss: 0.507316\n",
      "loss: 0.493078\n",
      "loss: 0.480530\n",
      "loss: 0.469397\n",
      "loss: 0.459457\n",
      "loss: 0.450532\n",
      "loss: 0.442473\n",
      "loss: 0.435161\n",
      "loss: 0.428495\n",
      "loss: 0.422391\n",
      "loss: 0.416779\n",
      "loss: 0.411600\n",
      "loss: 0.406802\n",
      "loss: 0.402345\n",
      "loss: 0.398190\n",
      "loss: 0.394308\n",
      "loss: 0.390669\n",
      "loss: 0.387251\n",
      "loss: 0.384032\n",
      "loss: 0.380996\n",
      "loss: 0.378124\n",
      "loss: 0.375405\n",
      "loss: 0.372825\n",
      "loss: 0.370372\n",
      "loss: 0.368038\n",
      "loss: 0.365812\n",
      "loss: 0.363688\n",
      "loss: 0.361658\n",
      "loss: 0.359715\n",
      "loss: 0.357853\n",
      "loss: 0.356068\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "data = df.as_matrix()\n",
    "\n",
    "y = data[:, 0]\n",
    "X = data[:, 1:].astype(np.float64)\n",
    "train_num = 41000\n",
    "val_num = 1000\n",
    "X_train, y_train = X[:train_num], y[:train_num]\n",
    "X_val, y_val = X[train_num:], y[train_num:]\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_train.dtype, y_train.dtype)\n",
    "print(X_val.shape, y_val.shape, X_val.dtype, y_val.dtype)\n",
    "\n",
    "\n",
    "mean_pixel = X_train.mean(axis=0)\n",
    "X_train -= mean_pixel\n",
    "X_val -= mean_pixel\n",
    "\n",
    "\n",
    "\n",
    "# Initializing our neural network\n",
    "def initialize_global_weights():\n",
    "    global W1, b1, W2, b2\n",
    "    N, D = train_num, 784\n",
    "    H, C = 500, 10\n",
    "    W1 = 0.001 * np.random.rand(D, H)\n",
    "    b1 = np.zeros(H)\n",
    "    W2 = 0.001 * np.random.rand(H, C)\n",
    "    b2 = np.zeros(C)\n",
    "\n",
    "initialize_global_weights()\n",
    "\n",
    "# training function\n",
    "def train_or_evaluate(X, y=None, loss_fn=None, lr=1e-3, reg=0.0):\n",
    "    global W1, W2, b1, b2\n",
    "    # forward pass\n",
    "    a = X.dot(W1) + b1\n",
    "    scores = a.dot(W2) + b2\n",
    "    if y is None:\n",
    "        return scores\n",
    "    loss, dscores = loss_fn(scores, y)\n",
    "    print('loss: %f' % loss)\n",
    "    # backward pass\n",
    "    dW2 = np.dot(a.T, dscores) + reg * W2\n",
    "    db2 = np.sum(dscores, axis=0)\n",
    "    da = np.dot(dscores, W2.T)\n",
    "    db1 = np.sum(da, axis=0)\n",
    "    dW1 = np.dot(X.T, da) + reg * W1\n",
    "    # update params\n",
    "    W1 += - lr * dW1\n",
    "    W2 += - lr * dW2\n",
    "    b1 += - lr * db1\n",
    "    b2 += - lr * db2\n",
    "    return loss\n",
    "\n",
    "# Implementing softmax loss function\n",
    "def softmax(scores, y):\n",
    "    N = scores.shape[0]\n",
    "    scores = scores.copy()\n",
    "    scores -= np.max(scores, axis=1)[:, None]\n",
    "    probs = np.exp(scores)\n",
    "    probs /= np.sum(probs, axis=1)[:, None]\n",
    "    loss = np.sum(-np.log(probs[np.arange(N), y])) / N\n",
    "    \n",
    "    dscores = probs.copy()\n",
    "    dscores[np.arange(N), y] -= 1\n",
    "    \n",
    "    return loss, dscores\n",
    "\n",
    "# Use initialized weight to checkout train accuracy\n",
    "scores = train_or_evaluate(X_train)\n",
    "print((np.argmax(scores, axis=1) == y_train).mean())\n",
    "\n",
    "\n",
    "\n",
    "# Training 2-layer model\n",
    "num_iters = 50\n",
    "initialize_global_weights()\n",
    "for i in range(num_iters):\n",
    "    loss = train_or_evaluate(X_train, y_train, softmax, lr=1e-7, reg=1e-5)\n",
    "    if np.isinf(loss):\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8983414634146342 0.896\n"
     ]
    }
   ],
   "source": [
    "# Checking train accuracy and val accuracy using trained weight\n",
    "train_scores = train_or_evaluate(X_train)\n",
    "train_acc = (np.argmax(train_scores, axis=1) == y_train).mean()\n",
    "val_scores = train_or_evaluate(X_val)\n",
    "val_acc = (np.argmax(val_scores, axis=1) == y_val).mean() \n",
    "print(train_acc, val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
